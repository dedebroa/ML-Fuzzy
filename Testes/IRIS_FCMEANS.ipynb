{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a5c3d6e-8c67-4b56-bdac-7b13e3438fa2",
   "metadata": {},
   "source": [
    "### INSTALAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a640e26-83a7-49f4-a162-574178606624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\venv\\ilumpy\\lib\\site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668e89b-8f74-423b-b715-d495150bbee0",
   "metadata": {},
   "source": [
    "> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4b676d-ca37-425c-b2b0-bcd4c44d160b",
   "metadata": {},
   "source": [
    "### IMPORTAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd46483-cf6d-40e6-b181-d24303642ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt  \n",
    "import sklearn\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from fcmeans import FCM\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ea575-cbb2-4d69-b1b9-d3b5d51219ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563a08d4-ab62-41e3-90c4-b7a6dccd37ee",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63054398-76a9-4392-9fa2-9d38b9284dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n",
      "\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "# variable information \n",
    "print(iris.variables) \n",
    "print()\n",
    "print(iris.variables)\n",
    "print()\n",
    "print(iris.feature_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7d356b-cfeb-4d9e-85c9-e6ebc461781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'published_in': 'Significance, 2021', 'year': 2021, 'url': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'doi': '1740-9713.01589'}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "   feature_0  feature_1  feature_2  feature_3       target\n",
      "0        NaN        NaN        NaN        NaN  Iris-setosa\n",
      "1        NaN        NaN        NaN        NaN  Iris-setosa\n",
      "2        NaN        NaN        NaN        NaN  Iris-setosa\n",
      "3        NaN        NaN        NaN        NaN  Iris-setosa\n",
      "4        NaN        NaN        NaN        NaN  Iris-setosa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(iris.metadata)\n",
    "\n",
    "# Assuming metadata contains 'feature_names', use it\n",
    "feature_names = iris.metadata.get('feature_names', [f'feature_{i}' for i in range(iris.data.features.shape[1])])\n",
    "\n",
    "# Create a DataFrame with feature names\n",
    "iris_df = pd.DataFrame(data=iris.data.features, columns=feature_names)\n",
    "iris_df['target'] = iris.data.targets\n",
    "\n",
    "# Display the DataFrame\n",
    "print(iris_df.head())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cc4668-e2bb-4051-a337-fe0667d30d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua 'caminho/do/seu/iris.data' pelo caminho real do seu arquivo Iris.data e 'iris.csv' pelo nome desejado para o arquivo CSV de saída.\n",
    "input_file = 'C:\\\\JupyterLab\\\\PAPL-UFPE\\\\ML-Fuzzy\\\\Testes\\\\iris.data'\n",
    "output_file = 'iris.csv'\n",
    "\n",
    "# Carregue o arquivo no pandas\n",
    "data = pd.read_csv(input_file, header=None, names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class'])\n",
    "\n",
    "# Salve o dataframe como CSV\n",
    "data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1059e20-b477-42e1-befe-43b65332d148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #linhas, colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9634a4d-5244-4f58-b77d-65b0d0bf04e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head # 5 primeiras linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "313eb37d-22d8-4fb4-8086-5069a92edf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.tail of      sepal_length  sepal_width  petal_length  petal_width           class\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail # 5 últimas linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "498d1fc8-b900-40e7-a22a-3b0e480c9205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    4\n",
       "object     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.dtypes).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23bc8569-0d0c-455b-b351-7d5e11226bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalização\n",
    "for index in data.columns: # em suma, para as colunas do DataFrame, vamos analisar se os dados são numéricos\n",
    "    # se os dados forem numéricos, eles serão normalizados\n",
    "    if is_numeric_dtype(data[index][0]): # retomando uma função do pandas\n",
    "        data[index] = data[index]/max(data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56f6ab9b-9fc1-436b-b2ac-92fe55b9461a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width           class\n",
       "0        0.645570     0.795455      0.202899         0.08     Iris-setosa\n",
       "1        0.620253     0.681818      0.202899         0.08     Iris-setosa\n",
       "2        0.594937     0.727273      0.188406         0.08     Iris-setosa\n",
       "3        0.582278     0.704545      0.217391         0.08     Iris-setosa\n",
       "4        0.632911     0.818182      0.202899         0.08     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145      0.848101     0.681818      0.753623         0.92  Iris-virginica\n",
       "146      0.797468     0.568182      0.724638         0.76  Iris-virginica\n",
       "147      0.822785     0.681818      0.753623         0.80  Iris-virginica\n",
       "148      0.784810     0.772727      0.782609         0.92  Iris-virginica\n",
       "149      0.746835     0.681818      0.739130         0.72  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdd1a422-644d-4ac8-a4f5-ad3fde211ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['class'].value_counts()) # class = species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19c81a6-aa88-4846-8aaa-4ed6a6446fb2",
   "metadata": {},
   "source": [
    "> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2cf23-3649-453c-8ca1-e0ae2c5d950f",
   "metadata": {},
   "source": [
    "### TREINO E TESTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a386de0-89a6-4483-b8fc-2dee76608a24",
   "metadata": {},
   "source": [
    "'''\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    tamanho_teste = 0.3\n",
    "\n",
    "    indices = iris_df.index\n",
    "    indices_treino, indices_teste = train_test_split(\n",
    "        indices, test_size= tamanho_teste\n",
    "    )\n",
    "\n",
    "    df_treino = iris_df.loc[indices_treino]\n",
    "    df_teste = iris_df.loc[indices_teste]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc38abd-e62b-4b0b-b475-ff2f66a1f1b8",
   "metadata": {},
   "source": [
    "> <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b708d54-685d-4a59-b6af-4a2ce9f14f2b",
   "metadata": {},
   "source": [
    "### FUZZY C-MEANS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ddfb53-bee1-42d9-8991-22303d17c7e5",
   "metadata": {},
   "source": [
    "### REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80059ec5-4ce1-49d6-affd-8ec291353a4b",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "@software{dias2019fuzzy,\n",
    "  <br>author       = {Madson Luiz Dantas Dias},\n",
    "  <br>title        = {fuzzy-c-means: An implementation of Fuzzy $C$-means clustering algorithm.},\n",
    "  <br>month        = may,\n",
    "  <br>year         = 2019,\n",
    "  <br>publisher    = {Zenodo},\n",
    "  <br>doi          = {10.5281/zenodo.3066222},\n",
    "  <br>url          = {https://git.io/fuzzy-c-means}\n",
    "<br>}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923cd13e-7f83-462c-b48e-1c976b78a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testes\n",
    "import tqdm\n",
    "from typing import Optional, Dict, Union, Callable\n",
    "from enum import Enum\n",
    "from joblib import Parallel, delayed\n",
    "from numpy.typing import NDArray\n",
    "from pydantic import BaseModel, Extra, Field, validate_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba7d109-76d0-40f0-b74c-8cca4aeedf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--install-completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d971efe3-c4e9-4eba-9363-30b13e24e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceOptions(str, Enum):\n",
    "    euclidean = 'euclidean' # se eu n me engano precisa ser gaussiano né\n",
    "    #minkowski = 'minkowski'\n",
    "    #cosine = 'cosine'\n",
    "\n",
    "class FCM(BaseModel):\n",
    "    r\"\"\"Fuzzy C-means Model\n",
    "\n",
    "    Attributes:\n",
    "        n_clusters (int): The number of clusters to form as well as the number\n",
    "        of centroids to generate by the fuzzy C-means.\n",
    "        max_iter (int): Maximum number of iterations of the fuzzy C-means\n",
    "        algorithm for a single run.\n",
    "        m (float): Degree of fuzziness: $m \\in (1, \\infty)$.\n",
    "        error (float): Relative tolerance with regards to Frobenius norm of\n",
    "        the difference\n",
    "        in the cluster centers of two consecutive iterations to declare\n",
    "        convergence.\n",
    "        random_state (Optional[int]): Determines random number generation for\n",
    "        centroid initialization.\n",
    "        Use an int to make the randomness deterministic.\n",
    "        trained (bool): Variable to store whether or not the model has been\n",
    "        trained.\n",
    "\n",
    "    Returns:\n",
    "        FCM: A FCM model.\n",
    "\n",
    "    Raises:\n",
    "        ReferenceError: If called without the model being trained\n",
    "    \"\"\"\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.allow\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    n_clusters: int = Field(3, ge=1)\n",
    "    max_iter: int = Field(150, ge=1, le=1000)\n",
    "    m: float = Field(2.0, ge=1.0)\n",
    "    error: float = Field(1e-5, ge=1e-9)\n",
    "    random_state: Optional[int] = None\n",
    "    trained: bool = Field(False, const=True)\n",
    "    n_jobs: int = Field(1, ge=1)\n",
    "    verbose: Optional[bool] = False\n",
    "    distance: Optional[Union[DistanceOptions, Callable]] = DistanceOptions.euclidean\n",
    "    distance_params: Optional[Dict] = {}\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def fit(self, X: NDArray) -> None:\n",
    "        \"\"\"Train the fuzzy-c-means model\n",
    "\n",
    "        Args:\n",
    "            X (NDArray): Training instances to cluster.\n",
    "        \"\"\"\n",
    "        self.rng = np.random.default_rng(self.random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        self.u = self.rng.uniform(size=(n_samples, self.n_clusters))\n",
    "        self.u = self.u / np.tile(self.u.sum(axis=1)[np.newaxis].T, self.n_clusters)\n",
    "        for _ in tqdm.tqdm(\n",
    "            range(self.max_iter), desc=\"Training\", disable=not self.verbose\n",
    "        ):\n",
    "            u_old = self.u.copy()\n",
    "            self._centers = FCM._next_centers(X, self.u, self.m)\n",
    "            self.u = self.soft_predict(X)\n",
    "            # Stopping rule\n",
    "            if np.linalg.norm(self.u - u_old) < self.error:\n",
    "                break\n",
    "        self.trained = True\n",
    "        \n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def soft_predict(self, X: NDArray) -> NDArray:\n",
    "        \"\"\"Soft predict of FCM\n",
    "\n",
    "        Args:\n",
    "            X (NDArray): New data to predict.\n",
    "\n",
    "        Returns:\n",
    "            NDArray: Fuzzy partition array, returned as an array with\n",
    "            n_samples rows and n_clusters columns.\n",
    "        \"\"\"\n",
    "        temp = FCM._dist(X, self._centers, self.distance, self.distance_params) ** (2 / (self.m - 1))\n",
    "        u_dist = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(lambda data, col: (data[:, col] / data.T).sum(0))(temp, col)\n",
    "            for col in range(temp.shape[1])\n",
    "        )\n",
    "        u_dist = np.vstack(u_dist).T\n",
    "        return 1 / u_dist\n",
    "\n",
    "    @validate_arguments(config=dict(arbitrary_types_allowed=True))\n",
    "    def predict(self, X: NDArray) -> NDArray:\n",
    "        \"\"\"Predict the closest cluster each sample in X belongs to.\n",
    "\n",
    "        Args:\n",
    "            X (NDArray): New data to predict.\n",
    "\n",
    "        Raises:\n",
    "            ReferenceError: If it called without the model being trained.\n",
    "\n",
    "        Returns:\n",
    "            NDArray: Index of the cluster each sample belongs to.\n",
    "        \"\"\"\n",
    "        if self._is_trained():\n",
    "            X = np.expand_dims(X, axis=0) if len(X.shape) == 1 else X\n",
    "            return self.soft_predict(X).argmax(axis=-1)\n",
    "        raise ReferenceError(\n",
    "            \"You need to train the model. Run `.fit()` method to this.\"\n",
    "        )\n",
    "\n",
    "    def _is_trained(self) -> bool:\n",
    "        if self.trained:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def _dist(A: NDArray, B: NDArray, distance: str, distance_params: str) -> NDArray:\n",
    "        \"\"\"Compute the distance between two matrices\"\"\"\n",
    "        if isinstance(distance, Callable):\n",
    "            return distance(A, B, distance_params)\n",
    "        elif distance == 'minkowski':\n",
    "            return FCM._minkowski(A, B, distance_params.get(\"p\", 1.0))\n",
    "        elif distance == 'cosine':\n",
    "            return FCM._cosine_similarity(A, B)\n",
    "        else:\n",
    "            return FCM._euclidean(A, B)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _euclidean(A: NDArray, B: NDArray) -> NDArray:\n",
    "        \"\"\"Compute the euclidean distance between two matrices\"\"\"\n",
    "        return np.sqrt(np.einsum(\"ijk->ij\", (A[:, None, :] - B) ** 2))\n",
    "\n",
    "    @staticmethod\n",
    "    def _minkowski(A: NDArray, B: NDArray, p: float) -> NDArray:\n",
    "        \"\"\"Compute the minkowski distance between two matrices\"\"\"\n",
    "        return (np.einsum(\"ijk->ij\", (A[:, None, :] - B) ** p)) ** (1/p)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cosine_similarity(A: NDArray, B: NDArray) -> NDArray:\n",
    "        \"\"\"Compute the cosine similarity between two matrices\"\"\"\n",
    "        p1 = np.sqrt(np.sum(A**2,axis=1))[:,np.newaxis]\n",
    "        p2 = np.sqrt(np.sum(B**2,axis=1))[np.newaxis,:]\n",
    "        return np.dot(A,B.T) / (p1*p2)\n",
    "\n",
    "    @staticmethod\n",
    "    def _next_centers(X: NDArray, u: NDArray, m: float):\n",
    "        \"\"\"Update cluster centers\"\"\"\n",
    "        um = u**m\n",
    "        return (X.T @ um / np.sum(um, axis=0)).T\n",
    "\n",
    "    @property\n",
    "    def centers(self) -> NDArray:\n",
    "        if self._is_trained():\n",
    "            return self._centers\n",
    "        raise ReferenceError(\n",
    "            \"You need to train the model. Run `.fit()` method to this.\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def partition_coefficient(self) -> float:\n",
    "        \"\"\"Partition coefficient\n",
    "\n",
    "        Equation 12a of\n",
    "        [this paper](https://doi.org/10.1016/0098-3004(84)90020-7).\n",
    "        \"\"\"\n",
    "        if self._is_trained():\n",
    "            return np.mean(self.u**2)\n",
    "        raise ReferenceError(\n",
    "            \"You need to train the model. Run `.fit()` method to this.\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def partition_entropy_coefficient(self):\n",
    "        if self._is_trained():\n",
    "            return -np.mean(self.u * np.log2(self.u))\n",
    "        raise ReferenceError(\n",
    "            \"You need to train the model. Run `.fit()` method to this.\"\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ace928-5fdb-47ee-a8ad-0c93d23159cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o coeficiente de partição usado pela biblioteca não corresponde ao que tem no artigo do Prof., as equações são diferentes\n",
    "        # tipo realmente bem diferentes mesmo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad938c0d-cb7a-4611-8b80-d455ee55bde0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddd216-e7e3-48f1-8d32-c50c7aca1e28",
   "metadata": {},
   "source": [
    "### REFERÊNCIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c556e6-e459-4682-9ad9-74e65aec38df",
   "metadata": {},
   "source": [
    "@software{dias2019fuzzy,\n",
    "  author       = {Madson Luiz Dantas Dias},\n",
    "  title        = {fuzzy-c-means: An implementation of Fuzzy $C$-means clustering algorithm.},\n",
    "  month        = may,\n",
    "  year         = 2019,\n",
    "  publisher    = {Zenodo},\n",
    "  doi          = {10.5281/zenodo.3066222},\n",
    "  url          = {https://git.io/fuzzy-c-means}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c78278-65cf-4922-857d-6760181ddf6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
